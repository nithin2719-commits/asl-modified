<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SignFlow - ASL Video Call</title>
    <link rel="stylesheet" href="/static/css/style.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
</head>
<body>
    <div class="call-container">
        <!-- Enhanced Header with SignFlow Branding -->
        <div class="call-header">
            <div class="brand-info">
                <div class="brand-logo">
                    <i class="fas fa-sign-language"></i>
                    <span class="brand-name">SignFlow</span>
                </div>
                <div class="call-info">
                    <h2>ASL Video Call</h2>
                    <div class="call-status">
                        <span class="status-dot connected"></span>
                        <span>Connected</span>
                    </div>
                </div>
            </div>
        </div>

        <!-- Main Video Area -->
        <div class="video-area">
            <div class="floating-controls">
                <button class="control-pill" id="logout-btn" title="Logout">
                    <i class="fas fa-right-from-bracket"></i>
                    <span class="btn-label">Logout</span>
                </button>
                <button class="control-pill" id="mute-btn" title="Toggle Microphone">
                    <i class="fas fa-microphone"></i>
                    <span class="btn-label">Mute</span>
                </button>
                <button class="control-pill" id="video-btn" title="Toggle Camera">
                    <i class="fas fa-video"></i>
                    <span class="btn-label">Video</span>
                </button>
                <button class="control-pill end-pill" id="end-call-btn" title="End Call">
                    <i class="fas fa-phone-slash"></i>
                    <span class="btn-label">End</span>
                </button>
            </div>

            <div class="call-stage">
                <!-- Meet-like framed Video Canvas -->
                <div class="remote-video-container">
                    <div class="interpreter-badge"><i class="fas fa-brain"></i> ASL Interpreter</div>
                    <video id="remote-peer" autoplay playsinline></video>
                    <!-- Local PIP -->
                    <div class="local-video-bubble">
                        <video id="local-video" autoplay muted playsinline></video>
                        <div class="participant-name">You</div>
                    </div>
                    <div class="participant-info">
                        <div class="participant-name">ASL Interpreter</div>
                        <div class="asl-output" id="asl-output">Ready for ASL detection...</div>
                        <div class="asl-sentence" id="asl-sentence">Sentence: </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- ASL Detection Canvas (Hidden) -->
        <canvas id="canvas" width="320" height="240" style="display:none;"></canvas>

        <!-- Call Duration -->
        <div class="call-duration">
            <span id="call-timer">00:00:00</span>
        </div>

        <!-- Camera Permission Prompt -->
        <div id="camera-prompt" class="camera-prompt">
            <div class="prompt-content">
                <h3>Camera Access Required</h3>
                <p>This app needs camera access to detect ASL signs.</p>
                <button id="start-camera-btn" class="btn-primary">Allow Camera Access</button>
                <p class="permission-help">
                    Click "Allow" when your browser asks for camera permissions.<br>
                    If blocked, click the camera icon in your browser's address bar.
                </p>
            </div>
        </div>
    </div>

    <script>
        const localVideo = document.getElementById('local-video');
        const remotePeerVideo = document.getElementById('remote-peer');
        remotePeerVideo.muted = true; // allow autoplay without user gesture
        remotePeerVideo.playsInline = true;
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const aslOutput = document.getElementById('asl-output');
        const aslSentence = document.getElementById('asl-sentence');
        const callTimer = document.getElementById('call-timer');
        const muteBtn = document.getElementById('mute-btn');
        const videoBtn = document.getElementById('video-btn');
        const muteLabel = muteBtn.querySelector('.btn-label');
        const videoLabel = videoBtn.querySelector('.btn-label');
        const muteIcon = muteBtn.querySelector('i');
        const videoIcon = videoBtn.querySelector('i');
        const endCallBtn = document.getElementById('end-call-btn');
        const logoutBtn = document.getElementById('logout-btn');
        const cameraPrompt = document.getElementById('camera-prompt');
        const startCameraBtn = document.getElementById('start-camera-btn');
        const mirrorCanvas = true;
        const ROLE = "{{ username|default('')|lower }}";
        const controlPills = document.querySelectorAll('.control-pill');

        let callStartTime = Date.now();
        let timerInterval;
        let isMuted = false;
        let isVideoOff = false;
        localVideo.classList.toggle('mirrored', mirrorCanvas);

        // Button hover glow position
        controlPills.forEach(btn => {
            btn.addEventListener('mousemove', (e) => {
                const rect = btn.getBoundingClientRect();
                btn.style.setProperty('--x', `${e.clientX - rect.left}px`);
                btn.style.setProperty('--y', `${e.clientY - rect.top}px`);
            });
        });

        // Start call timer
        function startTimer() {
            timerInterval = setInterval(() => {
                const elapsed = Date.now() - callStartTime;
                const hours = Math.floor(elapsed / 3600000);
                const minutes = Math.floor((elapsed % 3600000) / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                callTimer.textContent = `${hours.toString().padStart(2, '0')}:${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
            }, 1000);
        }

        // Initialize camera
        async function initCamera() {
            try {
                // Check if camera permission is already granted
                const permissionStatus = await navigator.permissions.query({ name: 'camera' });
                console.log('Camera permission status:', permissionStatus.state);

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: 640, height: 480, facingMode: 'user' },
                    audio: true
                });

                localVideo.srcObject = stream;
                cameraPrompt.style.display = 'none';
                startTimer();
                startSignaling(stream);
                if (ROLE === 'primary') {
                    startASLDetection();
                } else {
                    aslOutput.textContent = 'Viewer mode: ASL prediction off.';
                }

                // Show success message
                aslOutput.textContent = 'Camera connected! Ready for ASL detection.';
                setTimeout(() => {
                    aslOutput.textContent = 'Ready for ASL detection...';
                }, 2000);

            } catch (error) {
                console.error('Error accessing camera:', error);

                let errorMessage = 'Camera access failed. ';
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Please click "Allow" when prompted, or enable camera in browser settings.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'No camera found. Please connect a camera and refresh.';
                } else if (error.name === 'NotReadableError') {
                    errorMessage += 'Camera is already in use by another application.';
                } else {
                    errorMessage += 'Please check camera permissions and try again.';
                }

                aslOutput.textContent = errorMessage;
                cameraPrompt.style.display = 'flex';
            }
        }

        // Manual camera start button
        startCameraBtn.addEventListener('click', () => {
            aslOutput.textContent = 'Requesting camera access...';
            initCamera();
        });

        // ASL Detection
        async function startASLDetection() {
            const stream = localVideo.srcObject;
            if (!stream) return;

            let inFlight = false;
            const interval = setInterval(async () => {
                if (inFlight) return;
                if (localVideo.videoWidth === 0) return;

                ctx.save();
                if (mirrorCanvas) {
                    ctx.translate(canvas.width, 0);
                    ctx.scale(-1, 1);
                }
                ctx.drawImage(localVideo, 0, 0, canvas.width, canvas.height);
                ctx.restore();
                const imageData = canvas.toDataURL('image/jpeg', 0.5);

                try {
                    inFlight = true;
                    const response = await fetch('/predict', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({ image: imageData })
                    });

                    const result = await response.json();
                    if (result.letter) {
                        aslOutput.textContent = `Detected: ${result.letter}`;
                    }
                    if (typeof result.sentence === 'string') {
                        aslSentence.textContent = `Sentence: ${result.sentence}`;
                    }
                } catch (error) {
                    console.error('Error detecting ASL:', error);
                } finally {
                    inFlight = false;
                }
            }, 200); // Faster detection
        }

        // Control buttons
        muteBtn.addEventListener('click', () => {
            const stream = localVideo.srcObject;
            if (stream) {
                const audioTrack = stream.getAudioTracks()[0];
                audioTrack.enabled = !audioTrack.enabled;
                isMuted = !isMuted;
                muteBtn.classList.toggle('active', isMuted);
                muteBtn.classList.toggle('pill-off', isMuted);
                muteLabel.textContent = isMuted ? 'Unmute' : 'Mute';
                muteIcon.className = isMuted ? 'fas fa-microphone-slash' : 'fas fa-microphone';
            }
        });

        videoBtn.addEventListener('click', () => {
            const stream = localVideo.srcObject;
            if (stream) {
                const videoTrack = stream.getVideoTracks()[0];
                videoTrack.enabled = !videoTrack.enabled;
                isVideoOff = !isVideoOff;
                videoBtn.classList.toggle('active', isVideoOff);
                videoBtn.classList.toggle('pill-off', isVideoOff);
                videoLabel.textContent = isVideoOff ? 'Turn Video On' : 'Video';
                videoIcon.className = isVideoOff ? 'fas fa-video-slash' : 'fas fa-video';
            }
        });

        endCallBtn.addEventListener('click', () => {
            if (localVideo.srcObject) {
                localVideo.srcObject.getTracks().forEach(track => track.stop());
            }
            clearInterval(timerInterval);
            window.location.href = '/';
        });

        logoutBtn.addEventListener('click', async () => {
            try {
                await fetch('/logout', { method: 'POST' });
            } catch (e) {
                console.error('Logout failed', e);
            }
            window.location.href = '/';
        });

        // Initialize on page load - show camera prompt instead of auto-starting
        window.addEventListener('load', () => {
            cameraPrompt.style.display = 'flex';
            aslOutput.textContent = 'Click "Allow Camera Access" to start ASL recognition.';
        });

        // ------------------ WebRTC Signaling ------------------
        let pc = null;
        let remoteStream = null;

        async function startSignaling(stream) {
            if (!ROLE || (ROLE !== 'primary' && ROLE !== 'secondary')) {
                alert('Unknown role. Only primary/secondary allowed.');
                return;
            }

            pc = new RTCPeerConnection({
                iceServers: [
                    { urls: 'stun:stun.l.google.com:19302' },
                    { urls: 'stun:stun1.l.google.com:19302' },
                    // Public TURN for testing; replace with your own for reliability
                    {
                        urls: [
                            'turn:openrelay.metered.ca:80',
                            'turn:openrelay.metered.ca:443',
                            'turn:openrelay.metered.ca:443?transport=tcp'
                        ],
                        username: 'openrelayproject',
                        credential: 'openrelayproject'
                    }
                ],
                iceTransportPolicy: 'all'
            });

            pc.addEventListener('connectionstatechange', () => {
                console.log('PC state', pc.connectionState);
                if (pc.connectionState === 'failed' || pc.connectionState === 'disconnected') {
                    aslOutput.textContent = 'Connection lost. Reload to retry.';
                    try { pc.restartIce(); } catch (e) { console.warn('restartIce failed', e); }
                }
            });

            // Send local tracks
            stream.getTracks().forEach(track => pc.addTrack(track, stream));

            // Remote track handler
            pc.addEventListener('track', (event) => {
                if (!remoteStream) {
                    remoteStream = new MediaStream();
                    remotePeerVideo.srcObject = remoteStream;
                }
                if (event.track) {
                    remoteStream.addTrack(event.track);
                }
                if (remotePeerVideo.paused) {
                    remotePeerVideo.play().catch(() => {});
                }
            });

            // ICE candidate handler (HTTP signaling)
            pc.addEventListener('icecandidate', (event) => {
                if (event.candidate) {
                    sendSignal({ type: 'candidate', candidate: event.candidate });
                }
            });

            // Offer/Answer flow over HTTP polling
            if (ROLE === 'secondary') {
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                sendSignal({ type: 'offer', sdp: offer });
            }
            pollSignals();
        }

        async function sendSignal(payload) {
            try {
                await fetch('/signal/send', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ role: ROLE, data: payload })
                });
            } catch (e) {
                console.error('sendSignal failed', e);
            }
        }

        async function pollSignals() {
            try {
                const res = await fetch(`/signal/recv?role=${ROLE}`);
                const { messages } = await res.json();
                for (const msg of messages) {
                    await handleSignal(msg);
                }
            } catch (e) {
                console.error('pollSignals failed', e);
            } finally {
                setTimeout(pollSignals, 500); // poll every 500ms
            }
        }

        async function handleSignal(data) {
            if (!pc) return;
            if (data.type === 'offer' && ROLE === 'primary') {
                await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
                const answer = await pc.createAnswer();
                await pc.setLocalDescription(answer);
                sendSignal({ type: 'answer', sdp: answer });
            } else if (data.type === 'answer' && ROLE === 'secondary') {
                await pc.setRemoteDescription(new RTCSessionDescription(data.sdp));
            } else if (data.type === 'candidate') {
                if (data.candidate) {
                    try {
                        await pc.addIceCandidate(new RTCIceCandidate(data.candidate));
                    } catch (err) {
                        console.error('addIceCandidate failed', err);
                    }
                }
            }
        }
    </script>
</body>
</html>
